{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpaCy Training an Additional NER Tag\n",
    "\n",
    "Training a new spacy english model to recognize a custom named entity recognition tag for dam names. Both CoreNLP and spaCys NER tags were inconsitently tagging what we would like to id as a possible entity of a dam. \n",
    "\n",
    "For training data we used the Stanford BRAT annotation web application and are parsing the ```x.ann``` files to create labels. The workflow is a modified version of what the spaCy docs recommend\n",
    "\n",
    "```\n",
    "# Note: If you're using an existing model, make sure to mix in examples of\n",
    "# other entity types that spaCy correctly recognized before. Otherwise, your\n",
    "# model might learn the new type, but \"forget\" what it previously knew.\n",
    "# https://explosion.ai/blog/pseudo-rehearsal-catastrophic-forgetting\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spacy version: 2.0.3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import plac\n",
    "import random\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import classification_report\n",
    "print('spacy version: %s' % spacy.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data \n",
    "\n",
    "\n",
    "__Brat mapping__\n",
    "\n",
    "Extracting labels from the brat annotations (note: we copied the sentence into the notes field for easier access and mapped the existing NER tags for our use).\n",
    "```\n",
    "BRAT NER Tag: \"PERSON\" = River NER \n",
    "\n",
    "BRAT NER Tag: \"ORGANIZATION\" = Dam NER\n",
    "```\n",
    "\n",
    "### Training Data (spaCy) Format\n",
    "\n",
    "```\n",
    "[\n",
    "    ( \"sentence\", {\n",
    "        \"entities\": \n",
    "            [(char_start, char_end, \"NER_TAG\")] \n",
    "                  }\n",
    "     )\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docid</th>\n",
       "      <th>end_idx</th>\n",
       "      <th>extraction</th>\n",
       "      <th>ner</th>\n",
       "      <th>sentence</th>\n",
       "      <th>start_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54d4f5abe138238471e7f468</td>\n",
       "      <td>337</td>\n",
       "      <td>South Fork Diversion Dam</td>\n",
       "      <td>Dam</td>\n",
       "      <td>Diversion dams were identified using comments ...</td>\n",
       "      <td>313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54d4f5abe138238471e7f468</td>\n",
       "      <td>31</td>\n",
       "      <td>Smith River</td>\n",
       "      <td>River</td>\n",
       "      <td>For example \" \" the Smith River \" \" VA at USGS...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      docid  end_idx                extraction    ner  \\\n",
       "0  54d4f5abe138238471e7f468      337  South Fork Diversion Dam    Dam   \n",
       "1  54d4f5abe138238471e7f468       31               Smith River  River   \n",
       "\n",
       "                                            sentence  start_idx  \n",
       "0  Diversion dams were identified using comments ...        313  \n",
       "1  For example \" \" the Smith River \" \" VA at USGS...         20  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_brat_ann(directory='./data/train'):\n",
    "    ''' Function to parse brat annotation files and return a dataframe\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    directory : directory\n",
    "        Brat annotation directory.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pandas dataframe\n",
    "        Containing document identifier, sentence, extraction word, indexes and ner.\n",
    "    '''\n",
    "    # List of annotations\n",
    "    files = os.listdir('./data/train')\n",
    "    \n",
    "    # Return struct\n",
    "    document_id, sentences, extractions, start_idxes, end_idxes, ner_tags = [], [], [], [], [], []\n",
    "        \n",
    "    for document in files:\n",
    "        if document.endswith('.txt') or document.endswith('S_Store'):\n",
    "            continue\n",
    "        f = open(os.path.join(directory, document)).readlines()\n",
    "        for idx, i in enumerate(f):\n",
    "            if idx % 2 != 1:\n",
    "                # parse\n",
    "                lab, ner, extract = i.split('\\t')\n",
    "                ner = ner.split()[0]\n",
    "                if ner == 'Organization': \n",
    "                    ner ='Dam'\n",
    "                else: ner = 'River'\n",
    "                sentence = f[idx + 1].split('\\t')[2]\n",
    "                start_idx = sentence.index(extract[:-1])            \n",
    "                end_idx = start_idx + len(extract[:-1])\n",
    "\n",
    "                # Toss into list to build dataframe\n",
    "                ner_tags.append(ner.split()[0])\n",
    "                document_id.append(document[:-4])\n",
    "                sentences.append(sentence)\n",
    "                extractions.append(extract.replace('\\n', ''))\n",
    "                start_idxes.append(start_idx)\n",
    "                end_idxes.append(end_idx)\n",
    "    return pd.DataFrame({'docid': document_id, \n",
    "                         'ner': ner_tags,\n",
    "                         'sentence': sentences,\n",
    "                         'extraction': extractions,\n",
    "                         'start_idx': start_idxes, \n",
    "                         'end_idx': end_idxes})\n",
    "df = parse_brat_ann()\n",
    "\n",
    "# Test indexes to make sure \\n\n",
    "# df.iloc[0]['sentence'][140:178]\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter Dam Only NER Tagged Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109 Dam Labels\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docid</th>\n",
       "      <th>end_idx</th>\n",
       "      <th>extraction</th>\n",
       "      <th>ner</th>\n",
       "      <th>sentence</th>\n",
       "      <th>start_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54d4f5abe138238471e7f468</td>\n",
       "      <td>337</td>\n",
       "      <td>South Fork Diversion Dam</td>\n",
       "      <td>Dam</td>\n",
       "      <td>Diversion dams were identified using comments ...</td>\n",
       "      <td>313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54d4f5abe138238471e7f468</td>\n",
       "      <td>100</td>\n",
       "      <td>Philpott Dam</td>\n",
       "      <td>Dam</td>\n",
       "      <td>For example \" \" the Smith River \" \" VA at USGS...</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54d4f5abe138238471e7f468</td>\n",
       "      <td>101</td>\n",
       "      <td>Roanoke Rapids Dam</td>\n",
       "      <td>Dam</td>\n",
       "      <td>In contrast \" \" the Roanoke River \" \" NC -LRB-...</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>54d4f5abe138238471e7f468</td>\n",
       "      <td>133</td>\n",
       "      <td>John H . Kerr Dam</td>\n",
       "      <td>Dam</td>\n",
       "      <td>Although many of the dams in the Roanoke are u...</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>54d4f5abe138238471e7f468</td>\n",
       "      <td>48</td>\n",
       "      <td>Smith Mountain Dam</td>\n",
       "      <td>Dam</td>\n",
       "      <td>In addition \" \" operations at Smith Mountain D...</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      docid  end_idx                extraction  ner  \\\n",
       "0  54d4f5abe138238471e7f468      337  South Fork Diversion Dam  Dam   \n",
       "2  54d4f5abe138238471e7f468      100              Philpott Dam  Dam   \n",
       "4  54d4f5abe138238471e7f468      101        Roanoke Rapids Dam  Dam   \n",
       "6  54d4f5abe138238471e7f468      133         John H . Kerr Dam  Dam   \n",
       "7  54d4f5abe138238471e7f468       48        Smith Mountain Dam  Dam   \n",
       "\n",
       "                                            sentence  start_idx  \n",
       "0  Diversion dams were identified using comments ...        313  \n",
       "2  For example \" \" the Smith River \" \" VA at USGS...         88  \n",
       "4  In contrast \" \" the Roanoke River \" \" NC -LRB-...         83  \n",
       "6  Although many of the dams in the Roanoke are u...        116  \n",
       "7  In addition \" \" operations at Smith Mountain D...         30  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = df[df['ner'] =='Dam']\n",
    "print('%d Dam Labels\\n' %test.shape[0])\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 87\n",
      "Testing: 22\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(test, test_size=0.2)\n",
    "print('Training: %d' %train.shape[0])\n",
    "print('Testing: %d' %test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spaCy data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA = []\n",
    "TEST_DATA = []\n",
    "\n",
    "for i in train.iterrows():\n",
    "    TRAIN_DATA.append((i[1]['sentence'], \n",
    "                  {'entities': [(i[1]['start_idx'], i[1]['end_idx'], i[1]['ner'])]}))\n",
    "for i in test.iterrows():\n",
    "    TEST_DATA.append((i[1]['sentence'], \n",
    "                  {'entities': [(i[1]['start_idx'], i[1]['end_idx'], i[1]['ner'])]}))\n",
    "#TRAIN_DATA[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See spacy docs for more info\n",
    "LABEL = 'Dam'\n",
    "def main(model=None, new_model_name='dam-ner', output_dir='./dam-ner-spacy', n_iter=100):\n",
    "    \"\"\"Set up the pipeline and entity recognizer, and train the new entity.\"\"\"\n",
    "    if model is not None:\n",
    "        nlp = spacy.load(model)  # load existing spaCy model\n",
    "        print(\"Loaded model '%s'\" % model)\n",
    "    else:\n",
    "        nlp = spacy.blank('en')  # create blank Language class\n",
    "        print(\"Created blank 'en' model\")\n",
    "\n",
    "    # Add entity recognizer to model if it's not in the pipeline\n",
    "    # nlp.create_pipe works for built-ins that are registered with spaCy\n",
    "    if 'ner' not in nlp.pipe_names:\n",
    "        ner = nlp.create_pipe('ner')\n",
    "        nlp.add_pipe(ner)\n",
    "    # otherwise, get it, so we can add labels to it\n",
    "    else:\n",
    "        ner = nlp.get_pipe('ner')\n",
    "\n",
    "    ner.add_label(LABEL)   # add new entity label to entity recognizer\n",
    "\n",
    "    # get names of other pipes to disable them during training\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
    "    with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "        optimizer = nlp.begin_training()\n",
    "        for itn in range(n_iter):\n",
    "            random.shuffle(TRAIN_DATA)\n",
    "            losses = {}\n",
    "            for text, annotations in TRAIN_DATA:\n",
    "                nlp.update([text], [annotations], sgd=optimizer, drop=0.35,\n",
    "                           losses=losses)\n",
    "            print(losses)\n",
    "\n",
    "    # save model to output directory\n",
    "    if output_dir is not None:\n",
    "        output_dir = Path(output_dir)\n",
    "        if not output_dir.exists():\n",
    "            output_dir.mkdir()\n",
    "        nlp.meta['name'] = new_model_name  # rename model\n",
    "        nlp.to_disk(output_dir)\n",
    "        print(\"Saved model to\", output_dir)\n",
    "\n",
    "        # test the saved model\n",
    "        #print(\"Loading from\", output_dir)\n",
    "        #nlp2 = spacy.load(output_dir)\n",
    "        #doc2 = nlp2(test_text)\n",
    "        #for ent in doc2.ents:\n",
    "            #print(ent.label_, ent.text)\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: Dam \n",
      "\n",
      "Text: Wiefrich Dam\n"
     ]
    }
   ],
   "source": [
    "# quick test\n",
    "nlp2 = spacy.load('./dam-ner-spacy')\n",
    "\n",
    "doc2 = nlp2('There was a dam, the Wiefrich Dam was removed in 2010.')\n",
    "for ent in doc2.ents:\n",
    "    print('Label: %s' %ent.label_, '\\n\\nText: %s' %ent.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missed:  Otsego City Dam\n",
      "Mississippi River Lock and Dam No . 26\n",
      "Plainwell Dam\n",
      "Roanoke Rapids Dam\n",
      "Dwinnell Dam\n",
      "Edwards Dam\n",
      "Aswan High Dam\n",
      "Roanoke Rapids Dam\n",
      "Iron Gate Dam\n",
      "Otsego City Dam\n",
      "Otsego City Dam\n",
      "Dwinnell Dam\n",
      "Dwinnell Dam\n",
      "Dwinnell Dam\n",
      "Otsego City Dam\n",
      "Dwinnell Dam\n",
      "Mississippi River Lock and Dam No . 26\n",
      "Missed:  Otsego City Dam\n",
      "Otsego City Dam\n",
      "Dwinnell Dam\n",
      "Edwards Dam\n",
      "Philpott Dam\n",
      "Missed:  Philpott Dam\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "found = 0\n",
    "pred = []\n",
    "for i in test.iterrows():\n",
    "    doc = nlp2(i[1]['sentence'])\n",
    "    \n",
    "    for ent in doc.ents:\n",
    "        if i[1]['extraction'] == ent.text:\n",
    "            print(ent.text)\n",
    "            found += 1\n",
    "            pred.append(ent.text)\n",
    "        else: \n",
    "            print('Missed: ', i[1]['extraction'])\n",
    "            pred.append('')\n",
    "        #print('Label: %s' %ent.label_, '\\n\\nText: %s' %ent.text)\n",
    "print(found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        precision    recall  f1-score   support\n",
      "\n",
      "                                             0.00      0.00      0.00         0\n",
      "                        Aswan High Dam       1.00      1.00      1.00         1\n",
      "                          Dwinnell Dam       1.00      1.00      1.00         6\n",
      "                           Edwards Dam       1.00      1.00      1.00         2\n",
      "                         Iron Gate Dam       1.00      1.00      1.00         1\n",
      "Mississippi River Lock and Dam No . 26       1.00      1.00      1.00         2\n",
      "                       Otsego City Dam       1.00      0.67      0.80         6\n",
      "                          Philpott Dam       1.00      1.00      1.00         1\n",
      "                         Plainwell Dam       1.00      1.00      1.00         1\n",
      "                    Roanoke Rapids Dam       1.00      1.00      1.00         2\n",
      "\n",
      "                           avg / total       1.00      0.91      0.95        22\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bserna/anaconda/envs/text/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test['extraction'], pred[:-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on development document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low Head\n",
      "Dam\n",
      "Pete Thompson\n",
      "Methods of Dam\n",
      "Passive Dam\n",
      "Channels Following Dam\n",
      "Passive Dam\n",
      "Passive Dam\n",
      "Stochastic Incipient Motion Criterion\n",
      "Open Channel Flow\n",
      "Water Data Coordination\n",
      "Hawkesville Dam\n",
      "Hawkesville Dam\n",
      "Huttonville Dam\n",
      "Huttonville Dam\n",
      "ELEVATION(m)\n",
      "Greenfield Dam\n"
     ]
    }
   ],
   "source": [
    "example_doc = nlp2(open('/Users/Shared/text/Amos_2008_Thesis.txt').read())\n",
    "\n",
    "for ent in example_doc.ents:\n",
    "    print(ent.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:text]",
   "language": "python",
   "name": "conda-env-text-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
