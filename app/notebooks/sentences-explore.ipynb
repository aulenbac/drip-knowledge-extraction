{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example GDD 📼\n",
    "\n",
    "Input: ```sentences_nlp352```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import psycopg2\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "from utils import connect_db, get_dams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences: 147287\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docid</th>\n",
       "      <th>sentid</th>\n",
       "      <th>wordidx</th>\n",
       "      <th>words</th>\n",
       "      <th>poses</th>\n",
       "      <th>ners</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5705014ccf58f18a4c0d6d61</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 2, 3, 4]</td>\n",
       "      <td>[Eos, ,, Vol, .]</td>\n",
       "      <td>[NNS, ,, NNP, .]</td>\n",
       "      <td>[O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5705014ccf58f18a4c0d6d61</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>[94, ,, No., 10, ,, 5, March, 2013, PAGE, 104,...</td>\n",
       "      <td>[CD, ,, NN, CD, ,, CD, NNP, CD, NN, CD, JJ, JJ...</td>\n",
       "      <td>[NUMBER, O, O, NUMBER, O, DATE, DATE, DATE, O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5705014ccf58f18a4c0d6d61</td>\n",
       "      <td>3</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>[Most, studies, of, solute, transport, through...</td>\n",
       "      <td>[JJS, NNS, IN, JJ, NN, IN, NNS, VBP, VBN, IN, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5705014ccf58f18a4c0d6d61</td>\n",
       "      <td>4</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>[However, ,, small, impoundments, ,, such, as,...</td>\n",
       "      <td>[RB, ,, JJ, NNS, ,, JJ, IN, DT, VBN, IN, NN, C...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5705014ccf58f18a4c0d6d61</td>\n",
       "      <td>5</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>[As, these, small, systems, mature, ,, the, im...</td>\n",
       "      <td>[IN, DT, JJ, NNS, VBP, ,, DT, NNS, VBP, IN, NN...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      docid  sentid  \\\n",
       "0  5705014ccf58f18a4c0d6d61       1   \n",
       "1  5705014ccf58f18a4c0d6d61       2   \n",
       "2  5705014ccf58f18a4c0d6d61       3   \n",
       "3  5705014ccf58f18a4c0d6d61       4   \n",
       "4  5705014ccf58f18a4c0d6d61       5   \n",
       "\n",
       "                                             wordidx  \\\n",
       "0                                       [1, 2, 3, 4]   \n",
       "1  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
       "2  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
       "3  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
       "4  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
       "\n",
       "                                               words  \\\n",
       "0                                   [Eos, ,, Vol, .]   \n",
       "1  [94, ,, No., 10, ,, 5, March, 2013, PAGE, 104,...   \n",
       "2  [Most, studies, of, solute, transport, through...   \n",
       "3  [However, ,, small, impoundments, ,, such, as,...   \n",
       "4  [As, these, small, systems, mature, ,, the, im...   \n",
       "\n",
       "                                               poses  \\\n",
       "0                                   [NNS, ,, NNP, .]   \n",
       "1  [CD, ,, NN, CD, ,, CD, NNP, CD, NN, CD, JJ, JJ...   \n",
       "2  [JJS, NNS, IN, JJ, NN, IN, NNS, VBP, VBN, IN, ...   \n",
       "3  [RB, ,, JJ, NNS, ,, JJ, IN, DT, VBN, IN, NN, C...   \n",
       "4  [IN, DT, JJ, NNS, VBP, ,, DT, NNS, VBP, IN, NN...   \n",
       "\n",
       "                                                ners  \n",
       "0                                       [O, O, O, O]  \n",
       "1  [NUMBER, O, O, NUMBER, O, DATE, DATE, DATE, O,...  \n",
       "2      [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]  \n",
       "3  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "4  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get dam names\n",
    "dams = get_dams()\n",
    "\n",
    "# Database connection\n",
    "df = connect_db()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remap_sent(sent): return ' '.join(sent)\n",
    "\n",
    "def n_sents(idx, df):\n",
    "    ''' Returns the surrounding sentences in rel to dataframe'''\n",
    "    start = idx\n",
    "    end = idx\n",
    "    if idx > 0:\n",
    "        start = idx-1\n",
    "    if idx < len(df):\n",
    "        end = idx+1\n",
    "    return(start, end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Candidate Passages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: Dam Removal Research ; Status and Prospects .\n",
      "CPU times: user 2 µs, sys: 1e+03 ns, total: 3 µs\n",
      "Wall time: 5.25 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3150"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cand_idx = []\n",
    "\n",
    "for idx, i in enumerate(df['docid']):\n",
    "    doc, sentid, wordidx, words, poses, ners = df.loc[idx]\n",
    "    \n",
    "    if 'Dam' in words or 'dam' in words and 'DATE' in ners:\n",
    "        cand_idx.append(idx)\n",
    "\n",
    "print('Sample: %s' %remap_sent(df['words'].iloc[cand_idx[1]]))\n",
    "%time len(cand_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labeling functions\n",
    "\n",
    "From snorkel tutorial work \n",
    "\n",
    "```python\n",
    "\n",
    "CandidateExtractor(Dam_Removal_Year, [ngrams, ngrams], [DateMatcher(), DictionaryMatch(d=rm)])\n",
    "\n",
    "\n",
    "def LF_removal_present(c):\n",
    "    rm = ['remove', 'removal', 'breach', 'destroyed', 'destroy', 'failed', \n",
    "          'removed', 'breached', 'removing', 'post-dam', 'demolition', 'demolish',\n",
    "          'demolished', 'razing', 'razed', 'raze']\n",
    "    for i in rm:\n",
    "        if i in get_left_tokens(c, window=20) or i in get_right_tokens(c, window=20):\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def LF_timeframe(c):\n",
    "    ''' LF to ensure the dam removal is within a timeframe'''\n",
    "    try: \n",
    "        c = int(c.year.get_span())\n",
    "        if c > 1890 and c < 2020:\n",
    "            return 1\n",
    "        else: return 0\n",
    "    except:\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "def LF_remove_in_sentence(c):\n",
    "    \"\"\"A simple example of a labeling function\"\"\"\n",
    "    return 1 if 'remove' in c[1].get_parent().words or 'removal' in c[1].get_parent().words else 0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def removal_present(series):\n",
    "    rm = ['remove', 'removal', 'breach', 'destroyed', 'destroy', 'failed', \n",
    "          'removed', 'breached', 'removing', 'post-dam', 'demolition', 'demolish',\n",
    "          'demolished', 'razing', 'razed', 'raze']\n",
    "    \n",
    "    doc, sentid, wordidx, words, poses, ners = series\n",
    "    \n",
    "    for i in rm:\n",
    "        if i in words:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "removal_present(df.iloc[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "flagged = []\n",
    "\n",
    "for i in cand_idx:\n",
    "    start, end = n_sents(i, df)\n",
    "    \n",
    "    for sent in [start, i, end]:\n",
    "        if removal_present(df.iloc[sent]) == 1:\n",
    "            flagged.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1828 labels found\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'-LRB- Journal of Geophysical Research‐Biogeosciences , doi :10.1029 / 2012JG002148 , 2013 -RRB- -- EB Powers et al. investigated solute transport at this site in an agricultural region of Wisconsin -LRB- left -RRB- before and -LRB- right -RRB- after dam removal .'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('%s labels found' %len(flagged))\n",
    "\n",
    "remap_sent(df['words'].iloc[flagged[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3.6]",
   "language": "python",
   "name": "conda-env-py3.6-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
